#!/usr/bin/env python
"""TaskTrace ç¦»çº¿åˆ†æè„šæœ¬ã€‚

ç”¨æ³•:
    python scripts/analyze_traces.py                    # åˆ†æä»Šå¤©çš„ trace
    python scripts/analyze_traces.py --last 7           # åˆ†ææœ€è¿‘ 7 å¤©
    python scripts/analyze_traces.py --date 2026-02-16  # åˆ†ææŒ‡å®šæ—¥æœŸ
    python scripts/analyze_traces.py --all              # åˆ†ææ‰€æœ‰ trace
    python scripts/analyze_traces.py --output report.md # è¾“å‡ºåˆ°æ–‡ä»¶

åŠŸèƒ½:
    - æ„å›¾è¯†åˆ«å‡†ç¡®ç‡ç»Ÿè®¡
    - å·¥å…·ä½¿ç”¨é¢‘ç‡åˆ†æ
    - å¤±è´¥æ¨¡å¼è¯†åˆ«
    - å±‚çº§å‡çº§é¢‘ç‡ç»Ÿè®¡
    - æ€§èƒ½æŒ‡æ ‡åˆ†æ
"""

from __future__ import annotations

import argparse
import json
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

# é»˜è®¤ trace ç›®å½•
DEFAULT_TRACE_DIR = Path.home() / ".winclaw" / "traces"


def load_traces(trace_dir: Path, days: int = 1, date_str: str | None = None, all_days: bool = False) -> list[dict[str, Any]]:
    """åŠ è½½ trace æ–‡ä»¶ã€‚

    Args:
        trace_dir: trace ç›®å½•
        days: åŠ è½½æœ€è¿‘ N å¤©
        date_str: æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)
        all_days: åŠ è½½æ‰€æœ‰æ–‡ä»¶

    Returns:
        trace è®°å½•åˆ—è¡¨
    """
    traces = []

    if date_str:
        # æŒ‡å®šæ—¥æœŸ
        trace_file = trace_dir / f"trace-{date_str}.jsonl"
        if trace_file.exists():
            traces.extend(_load_jsonl(trace_file))
    elif all_days:
        # æ‰€æœ‰æ–‡ä»¶
        for f in trace_dir.glob("trace-*.jsonl"):
            traces.extend(_load_jsonl(f))
    else:
        # æœ€è¿‘ N å¤©
        for i in range(days):
            d = datetime.now() - timedelta(days=i)
            trace_file = trace_dir / f"trace-{d.strftime('%Y-%m-%d')}.jsonl"
            if trace_file.exists():
                traces.extend(_load_jsonl(trace_file))

    return traces


def _load_jsonl(file_path: Path) -> list[dict[str, Any]]:
    """åŠ è½½ JSONL æ–‡ä»¶ã€‚"""
    records = []
    try:
        with open(file_path, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        records.append(json.loads(line))
                    except json.JSONDecodeError:
                        pass
    except FileNotFoundError:
        pass
    return records


def analyze_traces(traces: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†æ trace æ•°æ®ã€‚

    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    if not traces:
        return {"error": "æ²¡æœ‰æ‰¾åˆ° trace æ•°æ®"}

    result = {
        "total_traces": len(traces),
        "time_range": _get_time_range(traces),
        "intent_analysis": _analyze_intents(traces),
        "tool_analysis": _analyze_tools(traces),
        "failure_analysis": _analyze_failures(traces),
        "tier_analysis": _analyze_tiers(traces),
        "performance": _analyze_performance(traces),
    }

    return result


def _get_time_range(traces: list[dict[str, Any]]) -> dict[str, str]:
    """è·å–æ—¶é—´èŒƒå›´ã€‚"""
    timestamps = [t.get("timestamp", "") for t in traces if t.get("timestamp")]
    if not timestamps:
        return {"start": "N/A", "end": "N/A"}

    timestamps.sort()
    return {
        "start": timestamps[0][:19] if timestamps else "N/A",
        "end": timestamps[-1][:19] if timestamps else "N/A",
    }


def _analyze_intents(traces: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†ææ„å›¾è¯†åˆ«ã€‚"""
    intent_counter = Counter()
    confidence_sum = 0.0
    confidence_count = 0

    for t in traces:
        primary = t.get("intent_primary", "")
        if primary:
            intent_counter[primary] += 1

        confidence = t.get("intent_confidence", 0)
        if confidence > 0:
            confidence_sum += confidence
            confidence_count += 1

    return {
        "distribution": dict(intent_counter.most_common(10)),
        "avg_confidence": round(confidence_sum / confidence_count, 3) if confidence_count > 0 else 0,
        "unique_intents": len(intent_counter),
    }


def _analyze_tools(traces: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†æå·¥å…·ä½¿ç”¨ã€‚"""
    tool_counter = Counter()
    tool_success = defaultdict(int)
    tool_fail = defaultdict(int)
    tool_duration = defaultdict(list)

    for t in traces:
        for tc in t.get("tool_calls", []):
            func_name = tc.get("function_name", "unknown")
            tool_counter[func_name] += 1

            status = tc.get("status", "")
            if status == "success":
                tool_success[func_name] += 1
            else:
                tool_fail[func_name] += 1

            duration = tc.get("duration_ms", 0)
            if duration:
                tool_duration[func_name].append(duration)

    # è®¡ç®—å¹³å‡è€—æ—¶
    avg_duration = {}
    for tool, durations in tool_duration.items():
        if durations:
            avg_duration[tool] = round(sum(durations) / len(durations), 1)

    return {
        "usage_count": dict(tool_counter.most_common(15)),
        "success_rate": {
            tool: round(tool_success[tool] / (tool_success[tool] + tool_fail[tool]), 2)
            for tool in tool_counter
            if tool_success[tool] + tool_fail[tool] > 0
        },
        "avg_duration_ms": avg_duration,
        "total_calls": sum(tool_counter.values()),
        "unique_tools": len(tool_counter),
    }


def _analyze_failures(traces: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†æå¤±è´¥æ¨¡å¼ã€‚"""
    error_counter = Counter()
    consecutive_failures = Counter()
    failed_traces = 0

    for t in traces:
        # ç»Ÿè®¡é”™è¯¯ä¿¡æ¯
        for tc in t.get("tool_calls", []):
            if tc.get("status") in ("error", "timeout", "denied"):
                error_msg = tc.get("error", "unknown")[:50]  # æˆªå–å‰ 50 å­—ç¬¦
                error_counter[error_msg] += 1

        # ç»Ÿè®¡è¿ç»­å¤±è´¥
        max_fail = t.get("consecutive_failures_max", 0)
        if max_fail > 0:
            consecutive_failures[max_fail] += 1

        # ç»Ÿè®¡å¤±è´¥ trace
        if t.get("final_status") in ("error", "max_steps"):
            failed_traces += 1

    return {
        "common_errors": dict(error_counter.most_common(10)),
        "consecutive_failures_distribution": dict(sorted(consecutive_failures.items())),
        "failed_traces": failed_traces,
        "failure_rate": round(failed_traces / len(traces), 3) if traces else 0,
    }


def _analyze_tiers(traces: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†æå±‚çº§ä½¿ç”¨å’Œå‡çº§ã€‚"""
    tier_counter = Counter()
    upgrade_counter = Counter()

    for t in traces:
        tier = t.get("tool_tier", "")
        if tier:
            tier_counter[tier] += 1

        for upgrade in t.get("tier_upgrades", []):
            upgrade_counter[upgrade] += 1

    return {
        "tier_distribution": dict(tier_counter),
        "upgrade_count": dict(upgrade_counter),
        "upgrade_rate": round(sum(upgrade_counter.values()) / len(traces), 3) if traces else 0,
    }


def _analyze_performance(traces: list[dict[str, Any]]) -> dict[str, Any]:
    """åˆ†ææ€§èƒ½æŒ‡æ ‡ã€‚"""
    durations = []
    tokens = []
    steps = []

    for t in traces:
        if t.get("total_duration_ms"):
            durations.append(t["total_duration_ms"])
        if t.get("total_tokens"):
            tokens.append(t["total_tokens"])
        if t.get("total_steps"):
            steps.append(t["total_steps"])

    def _stats(values: list[float]) -> dict[str, float]:
        if not values:
            return {"avg": 0, "min": 0, "max": 0, "median": 0}
        sorted_vals = sorted(values)
        n = len(sorted_vals)
        return {
            "avg": round(sum(values) / n, 1),
            "min": round(min(values), 1),
            "max": round(max(values), 1),
            "median": round(sorted_vals[n // 2], 1),
        }

    return {
        "duration_ms": _stats(durations),
        "tokens": _stats(tokens),
        "steps": _stats(steps),
    }


def print_report(analysis: dict[str, Any], output_file: str | None = None) -> None:
    """æ‰“å°åˆ†ææŠ¥å‘Šã€‚"""
    lines = []

    lines.append("=" * 60)
    lines.append("WinClaw TaskTrace åˆ†ææŠ¥å‘Š")
    lines.append("=" * 60)

    if "error" in analysis:
        lines.append(f"\nâŒ {analysis['error']}")
        print("\n".join(lines))
        return

    # åŸºæœ¬ä¿¡æ¯
    lines.append(f"\nğŸ“Š æ€»è®¡: {analysis['total_traces']} æ¡è®°å½•")
    lines.append(f"ğŸ“… æ—¶é—´èŒƒå›´: {analysis['time_range']['start']} ~ {analysis['time_range']['end']}")

    # æ„å›¾åˆ†æ
    lines.append("\n" + "-" * 40)
    lines.append("ğŸ¯ æ„å›¾è¯†åˆ«åˆ†æ")
    lines.append("-" * 40)
    intent = analysis["intent_analysis"]
    lines.append(f"  å”¯ä¸€æ„å›¾æ•°: {intent['unique_intents']}")
    lines.append(f"  å¹³å‡ç½®ä¿¡åº¦: {intent['avg_confidence']}")
    lines.append("  åˆ†å¸ƒ:")
    for k, v in intent["distribution"].items():
        lines.append(f"    - {k}: {v}")

    # å·¥å…·åˆ†æ
    lines.append("\n" + "-" * 40)
    lines.append("ğŸ”§ å·¥å…·ä½¿ç”¨åˆ†æ")
    lines.append("-" * 40)
    tool = analysis["tool_analysis"]
    lines.append(f"  æ€»è°ƒç”¨æ¬¡æ•°: {tool['total_calls']}")
    lines.append(f"  å”¯ä¸€å·¥å…·æ•°: {tool['unique_tools']}")
    lines.append("  ä½¿ç”¨é¢‘ç‡:")
    for k, v in tool["usage_count"].items():
        rate = tool["success_rate"].get(k, "N/A")
        lines.append(f"    - {k}: {v} æ¬¡ (æˆåŠŸç‡: {rate})")

    # å¤±è´¥åˆ†æ
    lines.append("\n" + "-" * 40)
    lines.append("âŒ å¤±è´¥åˆ†æ")
    lines.append("-" * 40)
    fail = analysis["failure_analysis"]
    lines.append(f"  å¤±è´¥ trace æ•°: {fail['failed_traces']}")
    lines.append(f"  å¤±è´¥ç‡: {fail['failure_rate']}")
    if fail["common_errors"]:
        lines.append("  å¸¸è§é”™è¯¯:")
        for k, v in fail["common_errors"].items():
            lines.append(f"    - {k}: {v} æ¬¡")

    # å±‚çº§åˆ†æ
    lines.append("\n" + "-" * 40)
    lines.append("ğŸ“ˆ å±‚çº§åˆ†æ")
    lines.append("-" * 40)
    tier = analysis["tier_analysis"]
    lines.append(f"  å±‚çº§åˆ†å¸ƒ: {tier['tier_distribution']}")
    lines.append(f"  å‡çº§æ¬¡æ•°: {tier['upgrade_count']}")
    lines.append(f"  å‡çº§ç‡: {tier['upgrade_rate']}")

    # æ€§èƒ½åˆ†æ
    lines.append("\n" + "-" * 40)
    lines.append("âš¡ æ€§èƒ½æŒ‡æ ‡")
    lines.append("-" * 40)
    perf = analysis["performance"]
    lines.append(f"  è€—æ—¶(ms): avg={perf['duration_ms']['avg']}, median={perf['duration_ms']['median']}")
    lines.append(f"  Tokenæ•°: avg={perf['tokens']['avg']}, median={perf['tokens']['median']}")
    lines.append(f"  æ­¥éª¤æ•°: avg={perf['steps']['avg']}, median={perf['steps']['median']}")

    lines.append("\n" + "=" * 60)

    report = "\n".join(lines)

    if output_file:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(report)
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    else:
        print(report)


def main():
    parser = argparse.ArgumentParser(description="WinClaw TaskTrace ç¦»çº¿åˆ†æ")
    parser.add_argument(
        "--trace-dir",
        type=str,
        default=str(DEFAULT_TRACE_DIR),
        help=f"trace ç›®å½• (é»˜è®¤: {DEFAULT_TRACE_DIR})",
    )
    parser.add_argument(
        "--last",
        type=int,
        default=1,
        help="åˆ†ææœ€è¿‘ N å¤© (é»˜è®¤: 1)",
    )
    parser.add_argument(
        "--date",
        type=str,
        help="åˆ†ææŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)",
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="åˆ†ææ‰€æœ‰ trace æ–‡ä»¶",
    )
    parser.add_argument(
        "--output",
        type=str,
        help="è¾“å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="è¾“å‡º JSON æ ¼å¼",
    )

    args = parser.parse_args()

    trace_dir = Path(args.trace_dir)

    # åŠ è½½ traces
    traces = load_traces(
        trace_dir,
        days=args.last,
        date_str=args.date,
        all_days=args.all,
    )

    # åˆ†æ
    analysis = analyze_traces(traces)

    # è¾“å‡º
    if args.json:
        output = json.dumps(analysis, ensure_ascii=False, indent=2)
        if args.output:
            with open(args.output, "w", encoding="utf-8") as f:
                f.write(output)
            print(f"JSON å·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(output)
    else:
        print_report(analysis, args.output)


if __name__ == "__main__":
    main()
