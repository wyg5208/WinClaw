"""æ‰¹é‡è®ºæ–‡é˜…è¯»åˆ†æå·¥å…·ã€‚

æä¾›åŠ¨ä½œï¼š
- scan_folder: æ‰«æè®ºæ–‡æ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰è®ºæ–‡æ–‡ä»¶
- batch_import: æ‰¹é‡å¯¼å…¥è®ºæ–‡åˆ°å‘é‡çŸ¥è¯†åº“
- analyze_papers: æ‰¹é‡å¯¹è®ºæ–‡è¿›è¡Œå­¦æœ¯è§’åº¦åˆ†æ
- generate_report: ç”Ÿæˆè®ºæ–‡åˆ†ææ±‡æ€»æŠ¥å‘Š

ä¾èµ–ï¼š
- knowledge_rag: å‘é‡çŸ¥è¯†åº“ï¼ˆæ–‡æ¡£è§£æã€å…¥åº“ã€æ£€ç´¢ï¼‰
- doc_generator: æ–‡æ¡£ç”Ÿæˆï¼ˆç”Ÿæˆ Word æŠ¥å‘Šï¼‰
- å¤§æ¨¡å‹å¯¹è¯: è®ºæ–‡å†…å®¹åˆ†æ

è®¾è®¡ï¼š
- æ”¯æŒæ‰¹é‡å¤„ç†å¤§é‡è®ºæ–‡
- è‡ªåŠ¨æå–å­¦æœ¯ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€å¹´ä»½ã€æœŸåˆŠç­‰ï¼‰
- æŒ‰å­¦æœ¯è§„èŒƒåˆ†æç ”ç©¶é—®é¢˜ã€æ–¹æ³•ã€ç»“è®ºã€åˆ›æ–°ç‚¹
- ç”Ÿæˆç»“æ„åŒ–é˜…è¯»å¤§çº²å’Œæ±‡æ€»æŠ¥å‘Š
"""

from __future__ import annotations

import asyncio
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Any

from src.tools.base import ActionDef, BaseTool, ToolResult, ToolResultStatus

logger = logging.getLogger(__name__)

# æ”¯æŒçš„è®ºæ–‡æ–‡ä»¶ç±»å‹
PAPER_EXTENSIONS = {".pdf", ".docx", ".doc"}

# åˆ†ææŠ¥å‘Šè¾“å‡ºç›®å½•
DEFAULT_OUTPUT_DIR = "generated/paper_analysis"


class BatchPaperAnalyzerTool(BaseTool):
    """æ‰¹é‡è®ºæ–‡é˜…è¯»åˆ†æå·¥å…·ã€‚"""

    name = "batch_paper_analyzer"
    emoji = "ğŸ“š"
    title = "æ‰¹é‡è®ºæ–‡åˆ†æ"
    description = "æ‰¹é‡é˜…è¯»å’Œåˆ†æå­¦æœ¯è®ºæ–‡ï¼Œç”Ÿæˆé˜…è¯»å¤§çº²å’Œå­¦æœ¯å»ºè®®"
    timeout = 300  # æ‰¹é‡å¤„ç†éœ€è¦æ›´é•¿æ—¶é—´

    def __init__(
        self,
        knowledge_rag_tool=None,
        doc_generator_tool=None,
        llm_client=None,
        output_dir: str = "",
    ):
        """åˆå§‹åŒ–æ‰¹é‡è®ºæ–‡åˆ†æå·¥å…·ã€‚

        Args:
            knowledge_rag_tool: çŸ¥è¯†åº“å·¥å…·å®ä¾‹ï¼ˆç”¨äºæ–‡æ¡£å…¥åº“å’Œæ£€ç´¢ï¼‰
            doc_generator_tool: æ–‡æ¡£ç”Ÿæˆå·¥å…·å®ä¾‹ï¼ˆç”¨äºç”ŸæˆæŠ¥å‘Šï¼‰
            llm_client: å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆç”¨äºè®ºæ–‡åˆ†æï¼‰
            output_dir: è¾“å‡ºç›®å½•
        """
        super().__init__()
        self._knowledge_rag = knowledge_rag_tool
        self._doc_generator = doc_generator_tool
        self._llm_client = llm_client

        self.output_dir = Path(output_dir) if output_dir else Path(DEFAULT_OUTPUT_DIR)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # å­˜å‚¨åˆ†æç»“æœ
        self._analysis_results: dict[str, dict] = {}

    @property
    def llm_client(self):
        """è·å– LLM å®¢æˆ·ç«¯ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰ã€‚"""
        if self._llm_client is None:
            # å°è¯•è‡ªåŠ¨è·å– litellm å®¢æˆ·ç«¯
            try:
                import litellm
                self._llm_client = litellm
            except ImportError:
                pass
        return self._llm_client

    @property
    def knowledge_rag(self):
        """è·å–çŸ¥è¯†åº“å·¥å…·ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰ã€‚"""
        if self._knowledge_rag is None:
            from src.tools.knowledge_rag import KnowledgeRAGTool
            self._knowledge_rag = KnowledgeRAGTool()
        return self._knowledge_rag

    @property
    def doc_generator(self):
        """è·å–æ–‡æ¡£ç”Ÿæˆå·¥å…·ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰ã€‚"""
        if self._doc_generator is None:
            from src.tools.doc_generator import DocGeneratorTool
            self._doc_generator = DocGeneratorTool(output_dir=str(self.output_dir))
        return self._doc_generator

    def get_actions(self) -> list[ActionDef]:
        return [
            ActionDef(
                name="scan_folder",
                description="æ‰«æè®ºæ–‡æ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰è®ºæ–‡æ–‡ä»¶åˆ—è¡¨ã€‚æ”¯æŒ PDF å’Œ DOCX æ ¼å¼ã€‚",
                parameters={
                    "folder_path": {
                        "type": "string",
                        "description": "è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰",
                    },
                    "recursive": {
                        "type": "boolean",
                        "description": "æ˜¯å¦é€’å½’æ‰«æå­æ–‡ä»¶å¤¹ï¼Œé»˜è®¤ False",
                    },
                },
                required_params=["folder_path"],
            ),
            ActionDef(
                name="batch_import",
                description="æ‰¹é‡å°†è®ºæ–‡å¯¼å…¥åˆ°å‘é‡çŸ¥è¯†åº“ã€‚ä¼šè‡ªåŠ¨è§£æ PDF/DOCX æ–‡æ¡£å†…å®¹å¹¶å‘é‡åŒ–å­˜å‚¨ã€‚",
                parameters={
                    "folder_path": {
                        "type": "string",
                        "description": "è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„",
                    },
                    "recursive": {
                        "type": "boolean",
                        "description": "æ˜¯å¦é€’å½’æ‰«æå­æ–‡ä»¶å¤¹",
                    },
                },
                required_params=["folder_path"],
            ),
            ActionDef(
                name="analyze_papers",
                description="æ‰¹é‡å¯¹è®ºæ–‡è¿›è¡Œå­¦æœ¯è§’åº¦åˆ†æï¼Œæå–ç ”ç©¶é—®é¢˜ã€æ–¹æ³•ã€ç»“è®ºã€åˆ›æ–°ç‚¹ç­‰ï¼Œç”Ÿæˆé˜…è¯»å¤§çº²ã€‚",
                parameters={
                    "folder_path": {
                        "type": "string",
                        "description": "è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„",
                    },
                    "analysis_depth": {
                        "type": "string",
                        "description": "åˆ†ææ·±åº¦ï¼šbasic(åŸºç¡€) / detailed(è¯¦ç»†)ï¼Œé»˜è®¤ detailed",
                        "enum": ["basic", "detailed"],
                    },
                },
                required_params=["folder_path"],
            ),
            ActionDef(
                name="generate_report",
                description="ç”Ÿæˆè®ºæ–‡åˆ†ææ±‡æ€»æŠ¥å‘Šï¼ŒåŒ…å«æ‰€æœ‰è®ºæ–‡çš„æ ¸å¿ƒè§‚ç‚¹å’Œå­¦æœ¯å¼•ç”¨å»ºè®®ã€‚",
                parameters={
                    "folder_path": {
                        "type": "string",
                        "description": "è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„",
                    },
                    "title": {
                        "type": "string",
                        "description": "æŠ¥å‘Šæ ‡é¢˜ï¼Œé»˜è®¤'æ‰¹é‡è®ºæ–‡é˜…è¯»åˆ†ææŠ¥å‘Š'",
                    },
                    "format_type": {
                        "type": "string",
                        "description": "æŠ¥å‘Šæ ¼å¼ï¼šdocx æˆ– htmlï¼Œé»˜è®¤ docx",
                        "enum": ["docx", "html"],
                    },
                },
                required_params=["folder_path"],
            ),
            ActionDef(
                name="full_pipeline",
                description="å®Œæ•´å·¥ä½œæµï¼šæ‰«ææ–‡ä»¶å¤¹ -> æ‰¹é‡å…¥åº“ -> å­¦æœ¯åˆ†æ -> ç”ŸæˆæŠ¥å‘Šï¼Œä¸€æ­¥å®Œæˆæ‰€æœ‰æ­¥éª¤ã€‚",
                parameters={
                    "folder_path": {
                        "type": "string",
                        "description": "è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰",
                    },
                    "report_title": {
                        "type": "string",
                        "description": "ç”Ÿæˆçš„æŠ¥å‘Šæ ‡é¢˜",
                    },
                },
                required_params=["folder_path"],
            ),
        ]

    async def execute(self, action: str, params: dict[str, Any]) -> ToolResult:
        handlers = {
            "scan_folder": self._scan_folder,
            "batch_import": self._batch_import,
            "analyze_papers": self._analyze_papers,
            "generate_report": self._generate_report,
            "full_pipeline": self._full_pipeline,
        }

        handler = handlers.get(action)
        if handler is None:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"ä¸æ”¯æŒçš„åŠ¨ä½œ: {action}",
            )

        try:
            return handler(params)
        except Exception as e:
            import traceback
            logger.error(f"æ‰¹é‡è®ºæ–‡åˆ†æå¤±è´¥: {e}\n{traceback.format_exc()}")
            return ToolResult(status=ToolResultStatus.ERROR, error=str(e))

    # -------------------- åŠ¨ä½œå®ç° --------------------

    def _scan_folder(self, params: dict[str, Any]) -> ToolResult:
        """æ‰«æè®ºæ–‡æ–‡ä»¶å¤¹ã€‚"""
        folder_path = params.get("folder_path", "").strip()
        recursive = params.get("recursive", False)

        if not folder_path:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error="æ–‡ä»¶å¤¹è·¯å¾„ä¸èƒ½ä¸ºç©º",
            )

        folder = Path(folder_path)
        if not folder.exists():
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}",
            )
        if not folder.is_dir():
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"ä¸æ˜¯æ–‡ä»¶å¤¹: {folder_path}",
            )

        # æ‰«æè®ºæ–‡æ–‡ä»¶
        paper_files = []
        try:
            if recursive:
                for ext in PAPER_EXTENSIONS:
                    paper_files.extend(folder.rglob(f"*{ext}"))
            else:
                for ext in PAPER_EXTENSIONS:
                    paper_files.extend(folder.glob(f"*{ext}"))
        except Exception as e:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"æ‰«ææ–‡ä»¶å¤¹å¤±è´¥: {e}",
            )

        # å»é‡å¹¶æ’åº
        paper_files = sorted(set(paper_files), key=lambda x: x.name)

        if not paper_files:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output=f"æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°è®ºæ–‡æ–‡ä»¶: {folder_path}\næ”¯æŒçš„æ ¼å¼: {', '.join(PAPER_EXTENSIONS)}",
                data={"papers": [], "count": 0},
            )

        # ç”Ÿæˆæ–‡ä»¶ä¿¡æ¯
        papers_info = []
        for f in paper_files:
            size_kb = f.stat().st_size / 1024
            papers_info.append({
                "name": f.name,
                "path": str(f.resolve()),
                "size_kb": round(size_kb, 1),
                "type": f.suffix.lower(),
            })

        output_lines = [
            f"ğŸ“‚ æ–‡ä»¶å¤¹: {folder_path}",
            f"ğŸ“„ æ‰¾åˆ° {len(paper_files)} ç¯‡è®ºæ–‡ï¼š\n",
        ]
        for i, p in enumerate(papers_info, 1):
            output_lines.append(f"  {i}. {p['name']} ({p['size_kb']:.1f}KB)")

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(output_lines),
            data={"papers": papers_info, "count": len(papers_info)},
        )

    def _batch_import(self, params: dict[str, Any]) -> ToolResult:
        """æ‰¹é‡å¯¼å…¥è®ºæ–‡åˆ°å‘é‡çŸ¥è¯†åº“ã€‚"""
        # æ™ºèƒ½äº‹ä»¶å¾ªç¯å¤„ç†
        try:
            loop = asyncio.get_running_loop()
            # å¦‚æœæœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªä»»åŠ¡
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self._batch_import_async(params))
                return future.result()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨ asyncio.run
            return asyncio.run(self._batch_import_async(params))

    async def _batch_import_async(self, params: dict[str, Any]) -> ToolResult:
        """æ‰¹é‡å¯¼å…¥è®ºæ–‡åˆ°å‘é‡çŸ¥è¯†åº“ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰ã€‚"""
        folder_path = params.get("folder_path", "").strip()
        recursive = params.get("recursive", False)

        # å…ˆæ‰«ææ–‡ä»¶å¤¹
        scan_result = self._scan_folder({"folder_path": folder_path, "recursive": recursive})
        if not scan_result.is_success:
            return scan_result

        papers = scan_result.data.get("papers", [])
        if not papers:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output="æ²¡æœ‰éœ€è¦å¯¼å…¥çš„è®ºæ–‡",
            )

        # é€ä¸ªå¯¼å…¥
        success_count = 0
        failed_papers = []
        results = []

        for paper in papers:
            file_path = paper["path"]
            print(f"  å°è¯•å¯¼å…¥: {paper['name']}...")
            try:
                result = await self.knowledge_rag.execute("add_document", {"file_path": file_path})
                print(f"  å¯¼å…¥ {paper['name']}: {result.status}")
                if result.is_success:
                    success_count += 1
                    results.append({"paper": paper["name"], "status": "success"})
                else:
                    failed_papers.append(paper["name"])
                    results.append({"paper": paper["name"], "status": "failed", "error": result.error})
            except Exception as e:
                print(f"  âŒ å¯¼å…¥å¤±è´¥: {paper['name']}, é”™è¯¯: {e}")
                failed_papers.append(paper["name"])
                results.append({"paper": paper["name"], "status": "failed", "error": str(e)})

        output_lines = [
            f"ğŸ“¥ æ‰¹é‡å¯¼å…¥å®Œæˆ",
            f"   æˆåŠŸ: {success_count}/{len(papers)}",
        ]
        if failed_papers:
            output_lines.append(f"   å¤±è´¥: {', '.join(failed_papers)}")

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(output_lines),
            data={
                "total": len(papers),
                "success": success_count,
                "failed": len(failed_papers),
                "results": results,
            },
        )

    def _analyze_papers(self, params: dict[str, Any]) -> ToolResult:
        """æ‰¹é‡åˆ†æè®ºæ–‡ã€‚"""
        folder_path = params.get("folder_path", "").strip()
        analysis_depth = params.get("analysis_depth", "detailed")

        if not self.llm_client:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error="æœªé…ç½®å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚è¯·åœ¨åˆå§‹åŒ–æ—¶æä¾› llm_clientã€‚",
            )

        # æ‰«ææ–‡ä»¶å¤¹
        scan_result = self._scan_folder({"folder_path": folder_path})
        if not scan_result.is_success:
            return scan_result

        papers = scan_result.data.get("papers", [])
        if not papers:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output="æ²¡æœ‰éœ€è¦åˆ†æçš„è®ºæ–‡",
            )

        # å­˜å‚¨åˆ†æç»“æœ
        self._analysis_results = {}
        analysis_output = [f"ğŸ“Š å¼€å§‹åˆ†æ {len(papers)} ç¯‡è®ºæ–‡...\n"]

        for i, paper in enumerate(papers, 1):
            paper_name = paper["name"]
            analysis_output.append(f"  [{i}/{len(papers)}] æ­£åœ¨åˆ†æ: {paper_name}")

            try:
                # ä½¿ç”¨å¤§æ¨¡å‹åˆ†æè®ºæ–‡
                analysis = self._analyze_single_paper(paper["path"], analysis_depth)
                self._analysis_results[paper_name] = analysis
            except Exception as e:
                analysis_output.append(f"    âŒ åˆ†æå¤±è´¥: {e}")

        output_lines = [
            f"âœ… åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(papers)} ç¯‡è®ºæ–‡",
            "",
        ]
        for name, analysis in self._analysis_results.items():
            output_lines.append(f"  ğŸ“„ {name}")
            if analysis.get("title"):
                output_lines.append(f"     æ ‡é¢˜: {analysis['title']}")
            if analysis.get("one_sentence"):
                output_lines.append(f"     æ¦‚æ‹¬: {analysis['one_sentence']}")

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(output_lines),
            data={"analysis_results": self._analysis_results},
        )

    def _analyze_single_paper(self, file_path: str, depth: str) -> dict:
        """åˆ†æå•ç¯‡è®ºæ–‡ã€‚"""
        # è§£æè®ºæ–‡å†…å®¹
        from src.core.rag import DocumentParser
        parser = DocumentParser()
        parse_result = parser.parse(file_path)

        if not parse_result.success or not parse_result.content:
            return {"error": f"æ–‡æ¡£è§£æå¤±è´¥: {parse_result.error}"}

        # æˆªå–å†…å®¹ç”¨äºåˆ†æï¼ˆé¿å…è¶…å‡º token é™åˆ¶ï¼‰
        content = parse_result.content[:15000]  # ä¿ç•™è¶³å¤Ÿçš„å†…å®¹

        # æ„å»ºåˆ†ææç¤ºè¯
        if depth == "basic":
            prompt = f"""è¯·åˆ†æä»¥ä¸‹å­¦æœ¯è®ºæ–‡ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚ç”¨ä¸­æ–‡å›å¤ã€‚

è®ºæ–‡å†…å®¹ï¼š
{content}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼ˆJSON æ ¼å¼ï¼‰ï¼š
{{
    "title": "è®ºæ–‡æ ‡é¢˜",
    "authors": "ä½œè€…",
    "year": "å‘è¡¨å¹´ä»½",
    "venue": "æœŸåˆŠ/ä¼šè®®",
    "one_sentence": "ä¸€å¥è¯æ¦‚æ‹¬è®ºæ–‡æ ¸å¿ƒè´¡çŒ®",
    "research_question": "ç ”ç©¶é—®é¢˜",
    "method": "ç ”ç©¶æ–¹æ³•",
    "conclusion": "ä¸»è¦ç»“è®º",
    "innovation": "åˆ›æ–°ç‚¹",
    "limitations": "å±€é™æ€§"
}}
"""
        else:  # detailed
            prompt = f"""è¯·å¯¹ä»¥ä¸‹å­¦æœ¯è®ºæ–‡è¿›è¡Œæ·±åº¦å­¦æœ¯åˆ†æã€‚ç”¨ä¸­æ–‡å›å¤ã€‚

è®ºæ–‡å†…å®¹ï¼š
{content}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼ˆJSON æ ¼å¼ï¼‰ï¼š
{{
    "title": "è®ºæ–‡æ ‡é¢˜",
    "authors": "ä½œè€…",
    "year": "å‘è¡¨å¹´ä»½",
    "venue": "æœŸåˆŠ/ä¼šè®®",
    "one_sentence": "ä¸€å¥è¯æ¦‚æ‹¬è®ºæ–‡æ ¸å¿ƒè´¡çŒ®",
    "research_question": "ç ”ç©¶é—®é¢˜",
    "research_hypothesis": "ç ”ç©¶å‡è®¾",
    "method": "ç ”ç©¶æ–¹æ³•",
    "data_source": "æ•°æ®æ¥æº",
    "key_findings": "ä¸»è¦å‘ç°",
    "conclusion": "ä¸»è¦ç»“è®º",
    "contribution": "ä¸»è¦è´¡çŒ®",
    "innovation": "åˆ›æ–°ç‚¹ï¼ˆç†è®º/æ–¹æ³•/åº”ç”¨ï¼‰",
    "limitations": "ç ”ç©¶å±€é™æ€§",
    "related_work": "ç›¸å…³æ–‡çŒ®",
    "reading_time": "å»ºè®®é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰",
    "key_sections": "é‡ç‚¹ç« èŠ‚"
}}
"""

        # è°ƒç”¨å¤§æ¨¡å‹
        try:
            response = self.llm_client.chat.completions.create(
                model="glm-4-flash",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )
            import json
            import re

            # è§£æ JSON ç»“æœ
            content_text = response.choices[0].message.content
            # æå– JSON éƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*\}', content_text)
            if json_match:
                result = json.loads(json_match.group())
                return result
            else:
                return {"raw_analysis": content_text}
        except Exception as e:
            return {"error": f"åˆ†æå¤±è´¥: {e}"}

    def _generate_report(self, params: dict[str, Any]) -> ToolResult:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šã€‚"""
        # æ™ºèƒ½äº‹ä»¶å¾ªç¯å¤„ç†
        try:
            loop = asyncio.get_running_loop()
            # å¦‚æœæœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨çº¿ç¨‹æ± 
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self._generate_report_async(params))
                return future.result()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨ asyncio.run
            return asyncio.run(self._generate_report_async(params))

    async def _generate_report_async(self, params: dict[str, Any]) -> ToolResult:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰ã€‚"""
        folder_path = params.get("folder_path", "").strip()
        title = params.get("title", "æ‰¹é‡è®ºæ–‡é˜…è¯»åˆ†ææŠ¥å‘Š")
        format_type = params.get("format_type", "docx")

        # å¦‚æœæ²¡æœ‰é¢„å­˜çš„åˆ†æç»“æœï¼Œå…ˆè¿›è¡Œåˆ†æ
        if not self._analysis_results:
            # å°è¯•ä»çŸ¥è¯†åº“è·å–
            analyze_result = self._analyze_papers({
                "folder_path": folder_path,
                "analysis_depth": "detailed"
            })
            if not analyze_result.is_success:
                return analyze_result

        if not self._analysis_results:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output="æ²¡æœ‰åˆ†æç»“æœå¯ä¾›ç”ŸæˆæŠ¥å‘Š",
            )

        # æ„å»ºæŠ¥å‘Šå†…å®¹
        report_content = self._build_report_content(title, folder_path)

        # ç”Ÿæˆæ–‡æ¡£
        try:
            result = await self.doc_generator.execute("generate_document", {
                "content": report_content,
                "title": title,
                "format_type": format_type,
            })
            return result
        except Exception as e:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}",
            )

    def _build_report_content(self, title: str, folder_path: str) -> str:
        """æ„å»ºæŠ¥å‘Š Markdown å†…å®¹ã€‚"""
        from datetime import datetime

        lines = [
            f"# {title}",
            "",
            "## åŸºæœ¬ä¿¡æ¯",
            "",
            f"- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"- **æ¥æºæ–‡ä»¶å¤¹**: {folder_path}",
            f"- **åˆ†æè®ºæ–‡æ•°é‡**: {len(self._analysis_results)} ç¯‡",
            "",
            "---",
            "",
        ]

        # è®ºæ–‡æ¸…å•
        lines.append("## è®ºæ–‡æ¸…å•")
        lines.append("")
        lines.append("| åºå· | æ ‡é¢˜ | ä½œè€… | å¹´ä»½ | çŠ¶æ€ |")
        lines.append("|:---:|:---|:---|:---:|:---:|")

        for i, (name, analysis) in enumerate(self._analysis_results.items(), 1):
            paper_title = analysis.get("title", name)
            authors = analysis.get("authors", "-")
            year = analysis.get("year", "-")
            status = "âœ…" if "error" not in analysis else "âš ï¸"
            lines.append(f"| {i} | {paper_title} | {authors} | {year} | {status} |")

        lines.append("")

        # ä¸»é¢˜èšç±»ï¼ˆæŒ‰å¹´ä»½åˆ†ç»„ï¼‰
        lines.append("## è®ºæ–‡æ¦‚è§ˆ")
        lines.append("")
        for name, analysis in self._analysis_results.items():
            if "error" in analysis:
                continue
            paper_title = analysis.get("title", name)
            one_sentence = analysis.get("one_sentence", "-")
            method = analysis.get("method", "-")
            conclusion = analysis.get("conclusion", "-")

            lines.append(f"### {paper_title}")
            lines.append("")
            lines.append(f"**ä¸€å¥è¯æ¦‚æ‹¬**: {one_sentence}")
            lines.append("")
            lines.append(f"**ç ”ç©¶æ–¹æ³•**: {method}")
            lines.append("")
            lines.append(f"**ä¸»è¦ç»“è®º**: {conclusion}")
            lines.append("")

        # å­¦æœ¯å»ºè®®
        lines.append("## å­¦æœ¯å»ºè®®")
        lines.append("")
        lines.append("### è®ºæ–‡å¼•ç”¨å»ºè®®")
        lines.append("")
        for name, analysis in self._analysis_results.items():
            if "error" in analysis:
                continue
            paper_title = analysis.get("title", name)
            contribution = analysis.get("contribution", analysis.get("innovation", "-"))
            lines.append(f"**{paper_title}**")
            lines.append(f"- ä¸»è¦è´¡çŒ®: {contribution}")
            lines.append("")

        lines.append("### å†™ä½œç»„ç»‡å»ºè®®")
        lines.append("")
        lines.append("1. **æŒ‰ä¸»é¢˜ç»„ç»‡**: å°†è®ºæ–‡æŒ‰ç ”ç©¶ä¸»é¢˜åˆ†ç»„ï¼Œæ„å»ºæ¸…æ™°çš„è®ºè¯é€»è¾‘")
        lines.append("2. **æ–¹æ³•è®ºå¯¹æ¯”**: æ¯”è¾ƒä¸åŒè®ºæ–‡ä½¿ç”¨çš„ç ”ç©¶æ–¹æ³•ï¼Œåˆ†æä¼˜åŠ£åŠ¿")
        lines.append("3. **å¼•ç”¨ç­–ç•¥**: ä¼˜å…ˆå¼•ç”¨åˆ›æ–°æ€§å¼ºã€ç»“è®ºå¯é çš„è®ºæ–‡")
        lines.append("")

        return "\n".join(lines)

    def _full_pipeline(self, params: dict[str, Any]) -> ToolResult:
        """å®Œæ•´å·¥ä½œæµã€‚"""
        import asyncio

        folder_path = params.get("folder_path", "").strip()
        report_title = params.get("report_title", "æ‰¹é‡è®ºæ–‡é˜…è¯»åˆ†ææŠ¥å‘Š")

        if not folder_path:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error="æ–‡ä»¶å¤¹è·¯å¾„ä¸èƒ½ä¸ºç©º",
            )

        steps = [
            ("æ‰«ææ–‡ä»¶å¤¹", lambda: self._scan_folder({"folder_path": folder_path})),
            ("æ‰¹é‡å…¥åº“", lambda: self._batch_import({"folder_path": folder_path})),
            ("å­¦æœ¯åˆ†æ", lambda: self._analyze_papers({"folder_path": folder_path})),
            ("ç”ŸæˆæŠ¥å‘Š", lambda: self._generate_report({
                "folder_path": folder_path,
                "title": report_title,
            })),
        ]

        output_lines = ["ğŸš€ å¼€å§‹å®Œæ•´å·¥ä½œæµ\n"]

        for step_name, step_func in steps:
            output_lines.append(f"ğŸ“Œ æ­¥éª¤: {step_name}...")
            try:
                result = step_func()
                if result.is_success:
                    output_lines.append(f"   âœ… å®Œæˆ")
                else:
                    output_lines.append(f"   âš ï¸ {result.error}")
            except Exception as e:
                output_lines.append(f"   âŒ å¤±è´¥: {e}")

        output_lines.append("\nğŸ‰ å·¥ä½œæµå®Œæˆï¼")

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(output_lines),
        )


# ç”¨äºæµ‹è¯•
if __name__ == "__main__":
    import asyncio

    async def test():
        tool = BatchPaperAnalyzerTool()

        # æµ‹è¯•æ‰«æ
        result = await tool.execute("scan_folder", {
            "folder_path": "D:/papers",
        })
        print(result.output)

    asyncio.run(test())
