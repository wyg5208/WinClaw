"""è¯­éŸ³è¾“å…¥å·¥å…· - åŸºäºŽ Whisper çš„è¯­éŸ³è½¬æ–‡å­—

æ”¯æŒ:
- å®žæ—¶å½•éŸ³ï¼ˆç›´æŽ¥ä¼  numpy æ•°ç»„ç»™ Whisperï¼Œæ— éœ€ ffmpegï¼‰
- éŸ³é¢‘æ–‡ä»¶è½¬æ–‡å­—ï¼ˆWAV å¯ç”¨ scipy è¯»å–ï¼Œå…¶ä»–æ ¼å¼éœ€ ffmpegï¼‰
- å¤šè¯­è¨€è¯†åˆ«
- å¯é€‰æ¨¡åž‹å¤§å° (tiny/base/small/medium/large)

Phase 4.6 ä¼˜åŒ–ï¼š
- å»¶è¿Ÿå¯¼å…¥ï¼šwhisper/sounddevice/numpy/scipy ä»…åœ¨å®žé™…ä½¿ç”¨æ—¶å¯¼å…¥
- å¯åŠ¨é€Ÿåº¦å¤§å¹…æå‡
"""
import asyncio
import logging
import os
import shutil
import tempfile
from pathlib import Path
from typing import Any, Optional

logger = logging.getLogger(__name__)

# å»¶è¿Ÿå¯¼å…¥æ ‡è®°
VOICE_AVAILABLE: bool | None = None
FFMPEG_AVAILABLE: bool | None = None

# æ¨¡å—å¼•ç”¨ï¼ˆå»¶è¿ŸåŠ è½½åŽèµ‹å€¼ï¼‰
_whisper = None
_sd = None
_np = None
_read_wav = None
_write_wav = None


def _check_voice_dependencies() -> bool:
    """æ£€æŸ¥è¯­éŸ³ä¾èµ–æ˜¯å¦å¯ç”¨ï¼Œå»¶è¿Ÿå¯¼å…¥ã€‚"""
    global VOICE_AVAILABLE, _whisper, _sd, _np, _read_wav, _write_wav
    if VOICE_AVAILABLE is not None:
        return VOICE_AVAILABLE

    try:
        import whisper
        import sounddevice as sd
        import numpy as np
        from scipy.io.wavfile import read as read_wav
        from scipy.io.wavfile import write as write_wav

        _whisper = whisper
        _sd = sd
        _np = np
        _read_wav = read_wav
        _write_wav = write_wav
        VOICE_AVAILABLE = True
        logger.debug("è¯­éŸ³ä¾èµ–åŠ è½½æˆåŠŸ")
    except ImportError:
        VOICE_AVAILABLE = False
        logger.debug("è¯­éŸ³ä¾èµ–ä¸å¯ç”¨")

    return VOICE_AVAILABLE


def _check_ffmpeg() -> bool:
    """æ£€æµ‹ ffmpeg æ˜¯å¦å¯ç”¨ã€‚"""
    global FFMPEG_AVAILABLE
    if FFMPEG_AVAILABLE is None:
        FFMPEG_AVAILABLE = shutil.which("ffmpeg") is not None
    return FFMPEG_AVAILABLE


from .base import ActionDef, BaseTool, ToolResult, ToolResultStatus


class VoiceInputTool(BaseTool):
    """è¯­éŸ³è¾“å…¥å·¥å…· - ä½¿ç”¨ Whisper å°†è¯­éŸ³è½¬ä¸ºæ–‡å­—"""

    name = "voice_input"
    emoji = "ðŸŽ¤"
    title = "è¯­éŸ³è¾“å…¥"
    description = "è¯­éŸ³è½¬æ–‡å­—å·¥å…·,æ”¯æŒå®žæ—¶å½•éŸ³æˆ–ä»ŽéŸ³é¢‘æ–‡ä»¶è¯†åˆ«"

    def __init__(self):
        super().__init__()
        self._model: Optional[Any] = None
        self._model_name: str = "base"
        self._sample_rate: int = 16000
        # ä¸åœ¨åˆå§‹åŒ–æ—¶æ£€æŸ¥ä¾èµ–ï¼Œå»¶è¿Ÿåˆ°å®žé™…ä½¿ç”¨æ—¶

    def _check_available(self) -> bool:
        """æ£€æŸ¥è¯­éŸ³åŠŸèƒ½æ˜¯å¦å¯ç”¨ã€‚"""
        if not _check_voice_dependencies():
            raise ImportError(
                "è¯­éŸ³åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·å®‰è£…ä¾èµ–: pip install openai-whisper sounddevice scipy"
            )
        return True

    def _load_model(self, model_name: str = "base") -> Any:
        """å»¶è¿ŸåŠ è½½ Whisper æ¨¡åž‹"""
        self._check_available()
        if self._model is None or self._model_name != model_name:
            self._model_name = model_name
            self._model = _whisper.load_model(model_name)
        return self._model

    def get_actions(self) -> list[ActionDef]:
        return [
            ActionDef(
                name="record_and_transcribe",
                description="å½•åˆ¶éŸ³é¢‘å¹¶è½¬ä¸ºæ–‡å­—",
                parameters={
                    "duration": {
                        "type": "number",
                        "description": "å½•éŸ³æ—¶é•¿(ç§’),é»˜è®¤ 5 ç§’",
                        "default": 5,
                    },
                    "model": {
                        "type": "string",
                        "description": "Whisper æ¨¡åž‹ (tiny/base/small/medium/large),é»˜è®¤ base",
                        "default": "base",
                        "enum": ["tiny", "base", "small", "medium", "large"],
                    },
                    "language": {
                        "type": "string",
                        "description": "è¯­è¨€ä»£ç (å¦‚ zh/en),ç•™ç©ºè‡ªåŠ¨æ£€æµ‹",
                        "default": None,
                    },
                },
                required_params=[],
            ),
            ActionDef(
                name="transcribe_file",
                description="å°†éŸ³é¢‘æ–‡ä»¶è½¬ä¸ºæ–‡å­—",
                parameters={
                    "file_path": {
                        "type": "string",
                        "description": "éŸ³é¢‘æ–‡ä»¶è·¯å¾„(æ”¯æŒ wav/mp3/m4a ç­‰)",
                    },
                    "model": {
                        "type": "string",
                        "description": "Whisper æ¨¡åž‹",
                        "default": "base",
                        "enum": ["tiny", "base", "small", "medium", "large"],
                    },
                    "language": {
                        "type": "string",
                        "description": "è¯­è¨€ä»£ç ,ç•™ç©ºè‡ªåŠ¨æ£€æµ‹",
                        "default": None,
                    },
                },
                required_params=["file_path"],
            ),
            ActionDef(
                name="list_devices",
                description="åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡",
                parameters={},
                required_params=[],
            ),
        ]

    async def execute(self, action: str, params: dict[str, Any]) -> ToolResult:
        """æ‰§è¡Œè¯­éŸ³è¾“å…¥æ“ä½œ"""
        if action == "record_and_transcribe":
            return await self._record_and_transcribe(**params)
        elif action == "transcribe_file":
            return await self._transcribe_file(**params)
        elif action == "list_devices":
            return self._list_devices()
        else:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"æœªçŸ¥åŠ¨ä½œ: {action}",
                output=f"å¯ç”¨åŠ¨ä½œ: {[a.name for a in self.get_actions()]}",
            )

    async def _record_and_transcribe(
        self, duration: float = 5.0, model: str = "base", language: Optional[str] = None
    ) -> ToolResult:
        """å½•åˆ¶éŸ³é¢‘å¹¶è½¬æ–‡å­—ï¼ˆç›´æŽ¥ä¼  numpy æ•°ç»„ï¼Œæ— éœ€ ffmpegï¼‰"""
        try:
            # æ£€æŸ¥ä¾èµ–
            self._check_available()

            # å½•éŸ³
            duration = max(1, min(duration, 60))  # é™åˆ¶ 1-60 ç§’
            frames = int(duration * self._sample_rate)

            logger.info("å¼€å§‹å½•éŸ³: %.1f ç§’, é‡‡æ ·çŽ‡ %d", duration, self._sample_rate)

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œé˜»å¡žçš„å½•éŸ³æ“ä½œ
            loop = asyncio.get_event_loop()
            audio_data = await loop.run_in_executor(
                None, lambda: _sd.rec(frames, samplerate=self._sample_rate, channels=1, dtype="float32")
            )
            await loop.run_in_executor(None, _sd.wait)

            # è½¬ä¸ºä¸€ç»´ float32 numpy æ•°ç»„ (Whisper è¦æ±‚çš„æ ¼å¼)
            audio_data = audio_data.flatten().astype(_np.float32)

            logger.info("å½•éŸ³å®Œæˆ, æ•°æ®é•¿åº¦: %d, èŒƒå›´: [%.4f, %.4f]",
                        len(audio_data), audio_data.min(), audio_data.max())

            # åŠ è½½æ¨¡åž‹
            model_obj = await loop.run_in_executor(None, self._load_model, model)

            # ç›´æŽ¥å°† numpy æ•°ç»„ä¼ ç»™ Whisperï¼ˆæ— éœ€ ffmpegï¼‰
            transcribe_kwargs = {"fp16": False}
            if language:
                transcribe_kwargs["language"] = language

            result = await loop.run_in_executor(
                None, lambda: model_obj.transcribe(audio_data, **transcribe_kwargs)
            )

            text = result["text"].strip()
            detected_language = result.get("language", "unknown")

            logger.info("è½¬å½•å®Œæˆ: è¯­è¨€=%s, æ–‡å­—=%s", detected_language, text[:50])

            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output=f"å½•éŸ³è½¬å½•æˆåŠŸ (æ—¶é•¿: {duration}s, è¯­è¨€: {detected_language})",
                data={
                    "text": text,
                    "language": detected_language,
                    "duration": duration,
                    "model": model,
                },
            )

        except Exception as e:
            logger.exception("å½•éŸ³è½¬å½•å¤±è´¥")
            return ToolResult(status=ToolResultStatus.ERROR, error=f"å½•éŸ³è½¬å½•å¤±è´¥: {e}")

    def _load_audio_file(self, file_path: str):
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶ä¸º Whisper è¦æ±‚çš„ float32 numpy æ•°ç»„ã€‚

        ä¼˜å…ˆä½¿ç”¨ ffmpegï¼ˆæ”¯æŒæ‰€æœ‰æ ¼å¼ï¼‰ï¼Œè‹¥ä¸å¯ç”¨åˆ™ç”¨ scipy è¯»å– WAVã€‚
        """
        self._check_available()

        if _check_ffmpeg():
            # ffmpeg å¯ç”¨æ—¶ï¼Œä½¿ç”¨ whisper å†…ç½®åŠ è½½ï¼ˆæ”¯æŒæ‰€æœ‰æ ¼å¼ï¼‰
            return _whisper.load_audio(file_path)

        # ffmpeg ä¸å¯ç”¨ï¼Œç”¨ scipy è¯»å– WAV æ–‡ä»¶
        ext = Path(file_path).suffix.lower()
        if ext not in (".wav", ".wave"):
            raise RuntimeError(
                f"ä¸æ”¯æŒ {ext} æ ¼å¼ï¼ˆéœ€è¦ ffmpegï¼‰ã€‚"
                f"è¯·å®‰è£… ffmpeg æˆ–å°†æ–‡ä»¶è½¬ä¸º WAV æ ¼å¼ã€‚\n"
                f"å®‰è£…æ–¹æ³•: winget install Gyan.FFmpeg"
            )

        sample_rate, data = _read_wav(file_path)

        # è½¬ä¸º float32
        if data.dtype == _np.int16:
            audio = data.astype(_np.float32) / 32768.0
        elif data.dtype == _np.int32:
            audio = data.astype(_np.float32) / 2147483648.0
        elif data.dtype == _np.float32:
            audio = data
        else:
            audio = data.astype(_np.float32)

        # å¤šå£°é“è½¬å•å£°é“
        if audio.ndim > 1:
            audio = audio.mean(axis=1)

        # é‡é‡‡æ ·åˆ° 16kHz (Whisper è¦æ±‚)
        if sample_rate != 16000:
            # ç®€å•çº¿æ€§é‡é‡‡æ ·
            duration = len(audio) / sample_rate
            target_len = int(duration * 16000)
            indices = _np.linspace(0, len(audio) - 1, target_len)
            audio = _np.interp(indices, _np.arange(len(audio)), audio).astype(_np.float32)

        return audio

    async def _transcribe_file(
        self, file_path: str, model: str = "base", language: Optional[str] = None
    ) -> ToolResult:
        """å°†éŸ³é¢‘æ–‡ä»¶è½¬ä¸ºæ–‡å­—"""
        try:
            path = Path(file_path).expanduser().resolve()
            if not path.exists():
                return ToolResult(status=ToolResultStatus.ERROR, error=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

            # æ£€æŸ¥æ–‡ä»¶å¤§å° (é™åˆ¶ 50MB)
            file_size_mb = path.stat().st_size / (1024 * 1024)
            if file_size_mb > 50:
                return ToolResult(
                    status=ToolResultStatus.ERROR, error=f"æ–‡ä»¶è¿‡å¤§: {file_size_mb:.1f}MB (é™åˆ¶ 50MB)"
                )

            # åŠ è½½æ¨¡åž‹
            loop = asyncio.get_event_loop()
            model_obj = await loop.run_in_executor(None, self._load_model, model)

            # åŠ è½½éŸ³é¢‘æ–‡ä»¶ä¸º numpy æ•°ç»„
            audio_data = await loop.run_in_executor(None, self._load_audio_file, str(path))

            # è½¬å½•ï¼ˆä¼ å…¥ numpy æ•°ç»„ï¼Œæ— éœ€ ffmpegï¼‰
            transcribe_kwargs = {"fp16": False}
            if language:
                transcribe_kwargs["language"] = language

            result = await loop.run_in_executor(
                None, lambda: model_obj.transcribe(audio_data, **transcribe_kwargs)
            )

            text = result["text"].strip()
            detected_language = result.get("language", "unknown")

            ffmpeg_note = "" if _check_ffmpeg() else " (æ—  ffmpeg, ä»…æ”¯æŒ WAV)"
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output=f"æ–‡ä»¶è½¬å½•æˆåŠŸ: {path.name}{ffmpeg_note}",
                data={
                    "text": text,
                    "language": detected_language,
                    "file_path": str(path),
                    "file_size_mb": file_size_mb,
                    "model": model,
                },
            )

        except Exception as e:
            logger.exception("æ–‡ä»¶è½¬å½•å¤±è´¥")
            return ToolResult(status=ToolResultStatus.ERROR, error=f"æ–‡ä»¶è½¬å½•å¤±è´¥: {e}")

    def _list_devices(self) -> ToolResult:
        """åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡"""
        try:
            self._check_available()

            devices = _sd.query_devices()
            input_devices = []

            for i, dev in enumerate(devices):
                if dev["max_input_channels"] > 0:
                    input_devices.append(
                        {
                            "index": i,
                            "name": dev["name"],
                            "channels": dev["max_input_channels"],
                            "sample_rate": dev["default_samplerate"],
                        }
                    )

            default_device = _sd.query_devices(kind="input")

            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output=f"æ‰¾åˆ° {len(input_devices)} ä¸ªéŸ³é¢‘è¾“å…¥è®¾å¤‡",
                data={"devices": input_devices, "default": default_device["name"]},
            )

        except Exception as e:
            return ToolResult(status=ToolResultStatus.ERROR, error=f"æŸ¥è¯¢è®¾å¤‡å¤±è´¥: {e}")
