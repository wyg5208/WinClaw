"""Knowledge Â∑•ÂÖ∑ ‚Äî ÊñáÊ°£Áü•ËØÜÂ∫ìÔºàÁ¥¢Âºï‰∏éÊ£ÄÁ¥¢Ôºâ„ÄÇ

ÊîØÊåÅÂä®‰ΩúÔºö
- search_documents: ÊêúÁ¥¢Â∑≤Á¥¢ÂºïÁöÑÊñáÊ°£ÔºàÊåâÊñá‰ª∂ÂêçÊàñÂÜÖÂÆπÂÖ≥ÈîÆËØçÔºâ
- query_document_content: Êü•ËØ¢ÊñáÊ°£ÂÜÖÂÆπÁâáÊÆµÔºàÁÆÄÊòì RAGÔºâ

ÂÄüÈâ¥Êù•Ê∫êÔºöÂèÇËÄÉÈ°πÁõÆ_changoai/backend/tool_functions.py ÊñáÊ°£Ê£ÄÁ¥¢Áõ∏ÂÖ≥ÂáΩÊï∞
Â≠òÂÇ®‰ΩçÁΩÆÔºö~/.winclaw/winclaw_tools.dbÔºàdocuments Ë°®Ôºâ
ÊñáÊ°£Â≠òÊîæÔºö~/.winclaw/documents/ÔºàÁî®Êà∑Ê∑ªÂä†ÁöÑÊñáÊ°£ÂâØÊú¨Ôºâ

ËÆæËÆ°ËØ¥ÊòéÔºö
- ÈááÁî® SQLite LIKE ÊêúÁ¥¢ËÄåÈùûÂêëÈáèÊï∞ÊçÆÂ∫ìÔºåÂáèÂ∞ëÂ§ñÈÉ®‰æùËµñ
- ÊîØÊåÅ .txt / .md / .json / .csv / .log Á≠âÁ∫ØÊñáÊú¨Êñá‰ª∂
- ÊñáÊ°£ÂÜÖÂÆπÂ≠òÂÖ•Êï∞ÊçÆÂ∫ìÔºåÂéüÊñá‰ª∂ÂèØÈÄâ‰øùÁïôÂú® documents/ ÁõÆÂΩï
"""

from __future__ import annotations

import logging
import os
import sqlite3
from contextlib import contextmanager
from datetime import datetime
from pathlib import Path
from typing import Any, Generator

from src.tools.base import ActionDef, BaseTool, ToolResult, ToolResultStatus

logger = logging.getLogger(__name__)

_DEFAULT_DB = Path.home() / ".winclaw" / "winclaw_tools.db"
_DOC_DIR = Path.home() / ".winclaw" / "documents"

# ÊîØÊåÅÁ¥¢ÂºïÁöÑÊñá‰ª∂Êâ©Â±ïÂêç
_INDEXABLE_EXTS = {
    ".txt", ".md", ".json", ".csv", ".log", ".ini", ".cfg",
    ".yaml", ".yml", ".toml", ".xml", ".html", ".htm",
    ".py", ".js", ".ts", ".java", ".go", ".rs", ".c", ".cpp", ".h",
}

# ÊúÄÂ§ßÁ¥¢ÂºïÊñá‰ª∂Â§ßÂ∞è (2 MB)
_MAX_FILE_SIZE = 2 * 1024 * 1024


class KnowledgeTool(BaseTool):
    """ÊñáÊ°£Áü•ËØÜÂ∫ìÂ∑•ÂÖ∑„ÄÇ

    ÊîØÊåÅÂ∞ÜÊú¨Âú∞ÊñáÊú¨Êñá‰ª∂Á¥¢ÂºïÂà∞Áü•ËØÜÂ∫ìÔºå
    ÁÑ∂ÂêéÈÄöËøáÂÖ≥ÈîÆËØçÊêúÁ¥¢Êñá‰ª∂ÂêçÊàñÂÜÖÂÆπÁâáÊÆµ„ÄÇ
    """

    name = "knowledge"
    emoji = "üìö"
    title = "ÊñáÊ°£Áü•ËØÜÂ∫ì"
    description = "Á¥¢ÂºïÊú¨Âú∞ÊñáÊ°£Âπ∂ÊêúÁ¥¢ÂÜÖÂÆπÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÊ£ÄÁ¥¢ÂíåÊñáÊ°£ÂÜÖÂÆπÊü•ËØ¢"

    def __init__(self, db_path: str = "", doc_dir: str = ""):
        super().__init__()
        self._db_path = Path(db_path) if db_path else _DEFAULT_DB
        self._doc_dir = Path(doc_dir) if doc_dir else _DOC_DIR
        self._db_path.parent.mkdir(parents=True, exist_ok=True)
        self._doc_dir.mkdir(parents=True, exist_ok=True)
        self._init_db()

    @contextmanager
    def _conn(self) -> Generator[sqlite3.Connection, None, None]:
        conn = sqlite3.connect(str(self._db_path))
        try:
            yield conn
        finally:
            conn.close()

    def _init_db(self) -> None:
        with self._conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS documents (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    filename TEXT NOT NULL,
                    filepath TEXT NOT NULL UNIQUE,
                    file_size INTEGER DEFAULT 0,
                    content TEXT NOT NULL DEFAULT '',
                    indexed_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL
                )
            """)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_documents_filename
                ON documents(filename)
            """)
            conn.commit()

    # ------------------------------------------------------------------

    def get_actions(self) -> list[ActionDef]:
        return [
            ActionDef(
                name="index_document",
                description=(
                    "Â∞ÜÊú¨Âú∞Êñá‰ª∂Á¥¢ÂºïÂà∞Áü•ËØÜÂ∫ì„ÄÇÊîØÊåÅ .txt/.md/.json/.csv/.py Á≠âÊñáÊú¨Êñá‰ª∂„ÄÇ"
                    "Á¥¢ÂºïÂêéÂèØÈÄöËøá search_documents ÊêúÁ¥¢„ÄÇ"
                ),
                parameters={
                    "file_path": {
                        "type": "string",
                        "description": "Ë¶ÅÁ¥¢ÂºïÁöÑÊñá‰ª∂ÁªùÂØπË∑ØÂæÑ",
                    },
                },
                required_params=["file_path"],
            ),
            ActionDef(
                name="search_documents",
                description="ÊêúÁ¥¢Áü•ËØÜÂ∫ì‰∏≠ÁöÑÊñáÊ°£ÔºåÊåâÊñá‰ª∂ÂêçÊàñÂÜÖÂÆπÂÖ≥ÈîÆËØçÂåπÈÖç",
                parameters={
                    "query": {
                        "type": "string",
                        "description": "ÊêúÁ¥¢ÂÖ≥ÈîÆËØç",
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ËøîÂõûÊï∞ÈáèÔºåÈªòËÆ§ 10",
                    },
                },
                required_params=["query"],
            ),
            ActionDef(
                name="query_document_content",
                description=(
                    "Êü•ËØ¢ÊåáÂÆöÊñáÊ°£‰∏≠ÂåÖÂê´ÂÖ≥ÈîÆËØçÁöÑÂÜÖÂÆπÁâáÊÆµ„ÄÇ"
                    "ËøîÂõûÂåπÈÖçË°åÂèäÂÖ∂‰∏ä‰∏ãÊñá„ÄÇ"
                ),
                parameters={
                    "document_name": {
                        "type": "string",
                        "description": "ÊñáÊ°£Êñá‰ª∂ÂêçÔºàÊàñÈÉ®ÂàÜÂêçÁß∞Ôºâ",
                    },
                    "question": {
                        "type": "string",
                        "description": "Ë¶ÅÊü•ÊâæÁöÑÂÖ≥ÈîÆËØçÊàñÈóÆÈ¢ò",
                    },
                    "context_lines": {
                        "type": "integer",
                        "description": "ÊØè‰∏™ÂåπÈÖçÁÇπÂâçÂêéÊòæÁ§∫ÁöÑË°åÊï∞ÔºåÈªòËÆ§ 3",
                    },
                },
                required_params=["document_name", "question"],
            ),
            ActionDef(
                name="list_documents",
                description="ÂàóÂá∫Áü•ËØÜÂ∫ì‰∏≠Â∑≤Á¥¢ÂºïÁöÑÊâÄÊúâÊñáÊ°£",
                parameters={
                    "limit": {
                        "type": "integer",
                        "description": "ËøîÂõûÊï∞ÈáèÔºåÈªòËÆ§ 50",
                    },
                },
                required_params=[],
            ),
            ActionDef(
                name="remove_document",
                description="‰ªéÁü•ËØÜÂ∫ì‰∏≠ÁßªÈô§ÊñáÊ°£Á¥¢Âºï",
                parameters={
                    "document_id": {
                        "type": "integer",
                        "description": "ÊñáÊ°£ ID",
                    },
                },
                required_params=["document_id"],
            ),
        ]

    async def execute(self, action: str, params: dict[str, Any]) -> ToolResult:
        handlers = {
            "index_document": self._index_document,
            "search_documents": self._search_documents,
            "query_document_content": self._query_document_content,
            "list_documents": self._list_documents,
            "remove_document": self._remove_document,
        }
        handler = handlers.get(action)
        if handler is None:
            return ToolResult(status=ToolResultStatus.ERROR, error=f"‰∏çÊîØÊåÅÁöÑÂä®‰Ωú: {action}")
        try:
            return handler(params)
        except Exception as e:
            logger.error("Áü•ËØÜÂ∫ìÊìç‰ΩúÂ§±Ë¥•: %s", e)
            return ToolResult(status=ToolResultStatus.ERROR, error=str(e))

    # ------------------------------------------------------------------

    def _index_document(self, params: dict[str, Any]) -> ToolResult:
        file_path_str = params.get("file_path", "").strip()
        if not file_path_str:
            return ToolResult(status=ToolResultStatus.ERROR, error="Êñá‰ª∂Ë∑ØÂæÑ‰∏çËÉΩ‰∏∫Á©∫")

        fp = Path(file_path_str)
        if not fp.exists():
            return ToolResult(status=ToolResultStatus.ERROR, error=f"Êñá‰ª∂‰∏çÂ≠òÂú®: {fp}")
        if not fp.is_file():
            return ToolResult(status=ToolResultStatus.ERROR, error=f"‰∏çÊòØÊñá‰ª∂: {fp}")
        if fp.suffix.lower() not in _INDEXABLE_EXTS:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"‰∏çÊîØÊåÅÁöÑÊñá‰ª∂Á±ªÂûã: {fp.suffix}„ÄÇÊîØÊåÅ: {', '.join(sorted(_INDEXABLE_EXTS))}",
            )
        if fp.stat().st_size > _MAX_FILE_SIZE:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"Êñá‰ª∂ËøáÂ§ß ({fp.stat().st_size / 1024:.0f} KB)ÔºåÊúÄÂ§ßÊîØÊåÅ {_MAX_FILE_SIZE // 1024} KB",
            )

        # ËØªÂèñÂÜÖÂÆπ
        try:
            content = fp.read_text(encoding="utf-8", errors="replace")
        except Exception as e:
            return ToolResult(status=ToolResultStatus.ERROR, error=f"ËØªÂèñÊñá‰ª∂Â§±Ë¥•: {e}")

        now = datetime.now().isoformat()
        filepath_key = str(fp.resolve())

        with self._conn() as conn:
            # Ê£ÄÊü•ÊòØÂê¶Â∑≤Á¥¢ÂºïÔºàÊåâË∑ØÂæÑÂéªÈáçÔºâ
            existing = conn.execute(
                "SELECT id FROM documents WHERE filepath = ?", (filepath_key,)
            ).fetchone()

            if existing:
                # Êõ¥Êñ∞
                conn.execute("""
                    UPDATE documents SET filename=?, file_size=?, content=?, updated_at=?
                    WHERE filepath=?
                """, (fp.name, fp.stat().st_size, content, now, filepath_key))
                conn.commit()
                doc_id = existing[0]
                action_text = "Â∑≤Êõ¥Êñ∞"
            else:
                # Êñ∞Â¢û
                cursor = conn.execute("""
                    INSERT INTO documents (filename, filepath, file_size, content, indexed_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (fp.name, filepath_key, fp.stat().st_size, content, now, now))
                conn.commit()
                doc_id = cursor.lastrowid
                action_text = "Â∑≤Á¥¢Âºï"

        lines_count = content.count("\n") + 1
        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output=f"{action_text}: {fp.name} (ID:{doc_id}, {lines_count} Ë°å, {fp.stat().st_size / 1024:.1f} KB)",
            data={
                "document_id": doc_id, "filename": fp.name,
                "lines": lines_count, "size_bytes": fp.stat().st_size,
            },
        )

    def _search_documents(self, params: dict[str, Any]) -> ToolResult:
        query = params.get("query", "").strip()
        limit = min(params.get("limit", 10), 50)

        if not query:
            return ToolResult(status=ToolResultStatus.ERROR, error="ÊêúÁ¥¢ÂÖ≥ÈîÆËØç‰∏çËÉΩ‰∏∫Á©∫")

        pattern = f"%{query}%"
        with self._conn() as conn:
            rows = conn.execute("""
                SELECT id, filename, filepath, file_size,
                       SUBSTR(content, MAX(1, INSTR(LOWER(content), LOWER(?)) - 50), 200) as snippet
                FROM documents
                WHERE filename LIKE ? OR content LIKE ?
                ORDER BY updated_at DESC
                LIMIT ?
            """, (query, pattern, pattern, limit)).fetchall()

        if not rows:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output=f"Êú™ÊâæÂà∞ÂåÖÂê´ '{query}' ÁöÑÊñáÊ°£„ÄÇ",
                data={"results": [], "count": 0},
            )

        lines = [f"ÊâæÂà∞ {len(rows)} ‰∏™ÂåπÈÖçÊñáÊ°£Ôºö"]
        data_list = []
        for i, (did, fname, fpath, fsize, snippet) in enumerate(rows, 1):
            snippet_clean = snippet.replace("\n", " ").strip() if snippet else ""
            if len(snippet_clean) > 150:
                snippet_clean = snippet_clean[:150] + "..."
            lines.append(f"  {i}. üìÑ {fname} (ID:{did}, {fsize / 1024:.1f} KB)")
            if snippet_clean:
                lines.append(f"      ...{snippet_clean}...")
            data_list.append({
                "id": did, "filename": fname, "filepath": fpath,
                "size_bytes": fsize, "snippet": snippet_clean,
            })

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(lines),
            data={"results": data_list, "count": len(data_list), "query": query},
        )

    def _query_document_content(self, params: dict[str, Any]) -> ToolResult:
        doc_name = params.get("document_name", "").strip()
        question = params.get("question", "").strip()
        context_lines = params.get("context_lines", 3)

        if not doc_name or not question:
            return ToolResult(status=ToolResultStatus.ERROR, error="ÊñáÊ°£ÂêçÂíåÂÖ≥ÈîÆËØç‰∏çËÉΩ‰∏∫Á©∫")

        with self._conn() as conn:
            row = conn.execute(
                "SELECT id, filename, content FROM documents WHERE filename LIKE ? LIMIT 1",
                (f"%{doc_name}%",)
            ).fetchone()

        if not row:
            return ToolResult(
                status=ToolResultStatus.ERROR,
                error=f"Êú™ÊâæÂà∞ÂåπÈÖç '{doc_name}' ÁöÑÊñáÊ°£ÔºåËØ∑ÂÖàÁ¥¢ÂºïÊñá‰ª∂",
            )

        did, fname, content = row
        all_lines = content.split("\n")
        keyword_lower = question.lower()

        # ÊâæÂà∞ÊâÄÊúâÂåπÈÖçË°å
        matches = []
        for idx, line in enumerate(all_lines):
            if keyword_lower in line.lower():
                start = max(0, idx - context_lines)
                end = min(len(all_lines), idx + context_lines + 1)
                snippet = "\n".join(
                    f"{'>>>' if j == idx else '   '} {j + 1}: {all_lines[j]}"
                    for j in range(start, end)
                )
                matches.append({"line_number": idx + 1, "snippet": snippet})

        if not matches:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output=f"Âú® {fname} ‰∏≠Êú™ÊâæÂà∞ÂåÖÂê´ '{question}' ÁöÑÂÜÖÂÆπ„ÄÇ",
                data={"document": fname, "matches": [], "count": 0},
            )

        # ÊúÄÂ§öËøîÂõû 5 ‰∏™ÂåπÈÖç
        shown = matches[:5]
        lines_out = [f"Âú® {fname} ‰∏≠ÊâæÂà∞ {len(matches)} Â§ÑÂåπÈÖçÔºö"]
        for m in shown:
            lines_out.append(f"\n--- Á¨¨ {m['line_number']} Ë°å ---")
            lines_out.append(m["snippet"])

        if len(matches) > 5:
            lines_out.append(f"\n... ËøòÊúâ {len(matches) - 5} Â§ÑÂåπÈÖçÊú™ÊòæÁ§∫")

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(lines_out),
            data={
                "document": fname, "document_id": did,
                "matches": [{"line": m["line_number"]} for m in shown],
                "total_matches": len(matches),
            },
        )

    def _list_documents(self, params: dict[str, Any]) -> ToolResult:
        limit = min(params.get("limit", 50), 200)

        with self._conn() as conn:
            rows = conn.execute(
                "SELECT id, filename, filepath, file_size, indexed_at FROM documents "
                "ORDER BY updated_at DESC LIMIT ?",
                (limit,)
            ).fetchall()

        if not rows:
            return ToolResult(
                status=ToolResultStatus.SUCCESS,
                output="Áü•ËØÜÂ∫ì‰∏≠ÊöÇÊó†ÊñáÊ°£„ÄÇÂèØ‰ΩøÁî® index_document Ê∑ªÂä†Êñá‰ª∂„ÄÇ",
                data={"documents": [], "count": 0},
            )

        lines = [f"Áü•ËØÜÂ∫ì‰∏≠ÂÖ± {len(rows)} ‰∏™ÊñáÊ°£Ôºö"]
        data_list = []
        for i, (did, fname, fpath, fsize, indexed) in enumerate(rows, 1):
            lines.append(f"  {i}. üìÑ {fname} (ID:{did}, {fsize / 1024:.1f} KB, Á¥¢Âºï‰∫é {indexed[:10]})")
            data_list.append({
                "id": did, "filename": fname, "filepath": fpath,
                "size_bytes": fsize, "indexed_at": indexed,
            })

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output="\n".join(lines),
            data={"documents": data_list, "count": len(data_list)},
        )

    def _remove_document(self, params: dict[str, Any]) -> ToolResult:
        doc_id = params.get("document_id")
        if doc_id is None:
            return ToolResult(status=ToolResultStatus.ERROR, error="Áº∫Â∞ë document_id")

        with self._conn() as conn:
            row = conn.execute("SELECT filename FROM documents WHERE id = ?", (doc_id,)).fetchone()
            if not row:
                return ToolResult(status=ToolResultStatus.ERROR, error=f"ÊñáÊ°£‰∏çÂ≠òÂú®: ID {doc_id}")
            fname = row[0]
            conn.execute("DELETE FROM documents WHERE id = ?", (doc_id,))
            conn.commit()

        return ToolResult(
            status=ToolResultStatus.SUCCESS,
            output=f"Â∑≤‰ªéÁü•ËØÜÂ∫ìÁßªÈô§: {fname} (ID:{doc_id})",
            data={"document_id": doc_id, "deleted": True},
        )
