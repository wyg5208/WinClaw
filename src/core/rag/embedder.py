"""æœ¬åœ°å‘é‡åµŒå…¥å™¨ - åŸºäº sentence-transformersã€‚

ä½¿ç”¨æœ¬åœ° Embedding æ¨¡å‹ç”Ÿæˆå‘é‡ï¼Œæ”¯æŒç¦»çº¿ä½¿ç”¨ã€‚
é»˜è®¤æ¨¡å‹: sentence-transformers/all-MiniLM-L6-v2 (384ç»´ï¼Œå…è´¹å¼€æº)

ç¦»çº¿æ¨¡å¼è¯´æ˜ï¼š
1. å…ˆè¿è¡Œ download_embedding_model.py ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
2. è®¾ç½®ç¯å¢ƒå˜é‡ EMBEDDING_MODEL_PATH æŒ‡å‘æœ¬åœ°æ¨¡å‹è·¯å¾„
3. è®¾ç½®ç¯å¢ƒå˜é‡ TRANSFORMERS_OFFLINE=1 å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
"""

import logging
import os
from pathlib import Path
from typing import Optional, Union

logger = logging.getLogger(__name__)

# é»˜è®¤æ¨¡å‹
DEFAULT_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

# æ¨¡å‹ç¼“å­˜ç›®å½•
MODEL_CACHE_DIR = os.path.expanduser("~/.cache/huggingface/hub")

# æœ¬åœ°æ¨¡å‹ç›®å½•ï¼ˆé¡¹ç›®å†…ç½®ï¼‰
LOCAL_MODEL_DIR = Path(__file__).parent.parent.parent.parent / "resources" / "embedding_models"

# ä»ç¯å¢ƒå˜é‡è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
EMBEDDING_MODEL_PATH = os.environ.get("EMBEDDING_MODEL_PATH", "")

# æ˜¯å¦å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ True ä»¥é¿å…ç½‘ç»œè¯·æ±‚ï¼‰
FORCE_OFFLINE = os.environ.get("TRANSFORMERS_OFFLINE", "1").lower() in ("1", "true", "yes")


class Embedder:
    """æœ¬åœ°å‘é‡åµŒå…¥å™¨ã€‚"""

    def __init__(
        self,
        model_name: str = DEFAULT_MODEL,
        cache_folder: Optional[str] = None,
        device: Optional[str] = None,
        local_model_path: Optional[Union[str, Path]] = None,
        offline_mode: Optional[bool] = None,
    ):
        """åˆå§‹åŒ–åµŒå…¥å™¨ã€‚

        Args:
            model_name: HuggingFace æ¨¡å‹åç§°ï¼Œé»˜è®¤ all-MiniLM-L6-v2
            cache_folder: æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ ~/.cache/huggingface/hub
            device: è¿è¡Œè®¾å¤‡ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹© (cuda/cpu)
            local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆçº§ï¼šå‚æ•° > ç¯å¢ƒå˜é‡ > è‡ªåŠ¨æ£€æµ‹ï¼‰
            offline_mode: æ˜¯å¦å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        """
        self.model_name = model_name
        self.cache_folder = cache_folder or MODEL_CACHE_DIR
        self.device = device
        self._model = None
        self._embedding_function = None

        # ç¡®å®šæœ¬åœ°æ¨¡å‹è·¯å¾„
        self._local_model_path = self._resolve_local_model_path(local_model_path)

        # ç¡®å®šç¦»çº¿æ¨¡å¼
        self._offline_mode = offline_mode if offline_mode is not None else FORCE_OFFLINE

    def _resolve_local_model_path(self, local_model_path: Optional[Union[str, Path]]) -> Optional[Path]:
        """è§£ææœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚

        ä¼˜å…ˆçº§ï¼š
        1. æ„é€ å‡½æ•°å‚æ•° local_model_path
        2. ç¯å¢ƒå˜é‡ EMBEDDING_MODEL_PATH
        3. é¡¹ç›®å†…ç½®ç›®å½• resources/embedding_models/{model_name}
        4. è¿”å› Noneï¼ˆä½¿ç”¨ HuggingFace åœ¨çº¿æ¨¡å¼ï¼‰

        Returns:
            æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ– None
        """
        # ä¼˜å…ˆä½¿ç”¨å‚æ•°
        if local_model_path:
            path = Path(local_model_path)
            if path.exists():
                logger.info(f"ğŸ“Œ ä½¿ç”¨å‚æ•°æŒ‡å®šçš„æœ¬åœ°æ¨¡å‹: {path}")
                return path
            else:
                logger.warning(f"âš ï¸ å‚æ•°æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨: {path}")

        # å…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡
        if EMBEDDING_MODEL_PATH:
            path = Path(EMBEDDING_MODEL_PATH)
            if path.exists():
                logger.info(f"ğŸ“Œ ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„æœ¬åœ°æ¨¡å‹: {path}")
                return path
            else:
                logger.warning(f"âš ï¸ ç¯å¢ƒå˜é‡æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨: {path}")

        # æœ€åæ£€æŸ¥é¡¹ç›®å†…ç½®ç›®å½•
        model_dir_name = self.model_name.replace("/", "_")
        builtin_path = LOCAL_MODEL_DIR / model_dir_name
        if builtin_path.exists():
            logger.info(f"ğŸ“Œ ä½¿ç”¨é¡¹ç›®å†…ç½®æ¨¡å‹: {builtin_path}")
            return builtin_path

        # æ²¡æœ‰æ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå°†ä½¿ç”¨åœ¨çº¿æ¨¡å¼
        logger.info(f"ğŸ“Œ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå°†ä½¿ç”¨åœ¨çº¿æ¨¡å¼: {self.model_name}")
        return None

    @property
    def model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹ã€‚"""
        if self._model is None:
            self._load_model()
        return self._model

    def _load_model(self) -> None:
        """åŠ è½½ sentence-transformers æ¨¡å‹ã€‚

        ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œé¿å…ç½‘ç»œè¯·æ±‚ã€‚
        """
        try:
            from sentence_transformers import SentenceTransformer

            # è®¾ç½®ç¦»çº¿æ¨¡å¼ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self._offline_mode:
                os.environ["TRANSFORMERS_OFFLINE"] = "1"
                os.environ["HF_HUB_OFFLINE"] = "1"
                logger.info("ğŸ”’ ç¦»çº¿æ¨¡å¼å·²å¯ç”¨")

            # åˆ›å»ºç¼“å­˜ç›®å½•
            os.makedirs(self.cache_folder, exist_ok=True)

            # ç¡®å®šè¦åŠ è½½çš„æ¨¡å‹è·¯å¾„
            if self._local_model_path:
                # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
                model_path = str(self._local_model_path)
                logger.info(f"ğŸ“¥ åŠ è½½æœ¬åœ° Embedding æ¨¡å‹: {model_path}")
            else:
                # ä½¿ç”¨æ¨¡å‹åç§°ï¼ˆå¯èƒ½åœ¨çº¿ä¸‹è½½ï¼‰
                model_path = self.model_name
                logger.info(f"ğŸ“¥ åŠ è½½ Embedding æ¨¡å‹: {model_path}")

            # åŠ è½½æ¨¡å‹
            self._model = SentenceTransformer(
                model_path,
                cache_folder=self.cache_folder,
                device=self.device,
            )
            logger.info(f"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸ (ç»´åº¦: {self._model.get_sentence_embedding_dimension()})")

        except ImportError:
            logger.error("âŒ sentence-transformers æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install sentence-transformers")
            raise
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ Embedding æ¨¡å‹å¤±è´¥: {e}")
            logger.error("ğŸ’¡ æç¤º: å¦‚æœç½‘ç»œä¸å¯ç”¨ï¼Œè¯·å…ˆè¿è¡Œ download_embedding_model.py ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°")
            raise

    def embed(self, texts: list[str], batch_size: int = 32) -> list[list[float]]:
        """å°†æ–‡æœ¬åˆ—è¡¨è½¬æ¢ä¸ºå‘é‡ã€‚

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°

        Returns:
            å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        try:
            embeddings = self.model.encode(
                texts,
                batch_size=batch_size,
                show_progress_bar=len(texts) > 100,
                convert_to_numpy=True,
            )
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")
            raise

    def embed_single(self, text: str) -> list[float]:
        """å°†å•ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å‘é‡
        """
        embeddings = self.embed([text])
        return embeddings[0] if embeddings else []

    def get_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦ã€‚"""
        return self.model.get_sentence_embedding_dimension()

    def is_ready(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½ã€‚"""
        return self._model is not None


# å…¨å±€å•ä¾‹
_default_embedder: Optional[Embedder] = None


def get_embedder(
    model_name: str = DEFAULT_MODEL,
    cache_folder: Optional[str] = None,
    device: Optional[str] = None,
    local_model_path: Optional[Union[str, Path]] = None,
    offline_mode: Optional[bool] = None,
) -> Embedder:
    """è·å–å…¨å±€åµŒå…¥å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰ã€‚

    Args:
        model_name: æ¨¡å‹åç§°
        cache_folder: ç¼“å­˜ç›®å½•
        device: è®¾å¤‡
        local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„
        offline_mode: æ˜¯å¦å¼ºåˆ¶ç¦»çº¿æ¨¡å¼

    Returns:
        Embedder å®ä¾‹
    """
    global _default_embedder

    if _default_embedder is None:
        _default_embedder = Embedder(
            model_name=model_name,
            cache_folder=cache_folder,
            device=device,
            local_model_path=local_model_path,
            offline_mode=offline_mode,
        )

    return _default_embedder


def reset_embedder() -> None:
    """é‡ç½®å…¨å±€åµŒå…¥å™¨ï¼ˆç”¨äºæµ‹è¯•æˆ–æ›´æ¢æ¨¡å‹ï¼‰ã€‚"""
    global _default_embedder
    _default_embedder = None
